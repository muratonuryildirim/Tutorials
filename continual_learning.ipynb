{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "continual_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMc7owBmRqSVZsmVPaO5SnT"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Continual Learning\n",
        "\n",
        "According to the traditional machine learning approach, it is assumed that data is already and always available. Hence, the model could work nicely if it is trained by the data on-hand. Recently, scientists and researchers realize that it is not the case. They, unfortunately, found that artificial neural networks have a tendency to forget. They even illustrated that the networks forget previously learned information completely and abruptly upon learning new information which is called **catastrophic forgetting**.\n",
        "\n",
        "When the trained model is faced with an unfamiliar observation or task, it could confuse and lead to wrong answers. Therefore, it has been suggested that this static approach should be replaced with the more dynamic one so that machine learning models can adapt themselves to the new tasks or experiments.\n",
        "\n",
        "Continual Learning is the concept to learn a model for a large number of tasks sequentially without forgetting knowledge obtained from the preceding tasks, where the data in the old tasks are not available anymore during the training of the new ones.\n",
        "\n",
        "Tasks should have the following criteria to be continuous:\n",
        "\n",
        "* Data (and tasks) become available only during the time.\n",
        "* No access to previously encountered data.\n",
        "* Constant computational and memory resources (efficiency)\n",
        "* Incremental development of ever more complex knowledge and skills (scalability)\n",
        "\n",
        "There are other also other approaches that should not be confused with the continual learning to make the machine learning systems more dynamic and adaptive:\n",
        "\n",
        "* Multi-Task Learning\n",
        "* Meta-Learning / Learning to\n",
        "Learn\n",
        "* Transfer Learning & Domain\n",
        "Adaptation\n",
        "* Online / Streaming Learning \n",
        "\n",
        "To sum up, continual learning aims find a well-generalized model that remembers past concepts while learning the new concepts as well. It is not an easy job since the model should understand which biased information should be removed and which biased information should be preserved. Continual learning also assumes that there will be no access to previously encountered data and tasks. That assumption is important from two different aspects: First, in a continuous environment, the thing that is gone is gone. It can not exist again. Second, from the resource aspect, it is not possible to store all the previous information the model has encountered before. As an example, an average human consumes approximately 50 GB/s while observing stuff which makes ~30240 TB of data after only a week."
      ],
      "metadata": {
        "id": "sCJr1cAglFcJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Catastrophic Forgetting\n",
        "\n",
        "Forgetting is something that is not just related to machines but it is part of the very nature of humans and the process of learning. It is actually important to forget the biased information or all information acquired over time in terms of effectiveness and efficiency. Models cannot remember everything and even if it remembers them it is just a waste of resource to remember things that are not useful to reach a particular goal.\n",
        "\n",
        "However, the level of forgetting is what matters here. The model should forget the unnecessary to generalize well yet it should retain the key information to 'learn'. The term **catastrophic forgetting**  means losing information completely and abruptly upon learning new information mostly due to the *gradient descent*. That is because, in the traditional approach, the model tries to minimize the loss **on a given task** which can be completely different for another task. Hence, continual learning shifts its standpoint a bit and it suggests that the model should try to minimize the loss **over the entire stream of task** which is represented as L<sub>$s$</sub>.\n",
        "\n",
        "The interesting and funny point here is this: the model could work perfectly if all the data at hand were fed to the model at once, yet when we split the data into smaller pieces and feed them into the model as a stream of tasks, the model is starting to forget. It is very remarkable to see how such a small change affects the performance of the model. However, it is not possible to have all the data at hand at once in a real case scenario which shows the motivation behind the continual learning and the significance of the catastrophic forgetting."
      ],
      "metadata": {
        "id": "RaQ-fnfCognu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Shifts in ML\n",
        "\n",
        "In the traditional offline machine leraning, data and its distrubtuion is fixed while in the real world scanerio data is something dynamic and can change over time. To define these kind of changes researchers have come up with different terms:\n",
        "* Covariate Shift (shift happens in inputs): P(X) - same input returns same output but inputs are changed a bit.\n",
        "* Prior Probabilty Shift (shift happpens in output): P(y) - same input returns same output but frequency or the distribution of the output is changed a bit.\n",
        "* Concept Shift (shift happpens in output): P(y|X) - same input does not return same output anymore. Model should adapt itself - means retraining is necessary.\n",
        "\n",
        "The first two terms are classified under a virtual drift which is concerned by continual learning since the shifts we encounter is just a the result of a sample or task selection order (or bias). Therefore, in the virtual drift case, it should be assumed that all the previous examples or the previous observations are still valid and we need to accumulate knowledge over time. The other term is classified under a real drift which mostly investigated by online learning and AutoML. To sum up, one should be able to identify the type of shift so that the necessary action can be taken.\n",
        "\n",
        "<img src=\"https://github.com/muratonuryildirim/Tutorials/blob/master/images/datashift.png?raw=true\" width=600>\n",
        "\n"
      ],
      "metadata": {
        "id": "M40lWcEkePuz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Common Assumptions in Continual Learning\n",
        "\n",
        "* *Shift is only virtual* which means forgetting is not needed only accumulation of knowledge would be enough.\n",
        "* *No conflicting evidence* that stands for one x value can be only \n",
        "valid for one y since we are modeling a mathematical function.\n",
        "* *Unbounded time between two experiences* which describes multiple time of training can possible for one experiment.\n",
        "* *Data processing valid in each experience* so that data in a given experience can be shuffled and processed freely."
      ],
      "metadata": {
        "id": "c5Rasq6nqmId"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Categorization of the Continual Learning Approaches\n",
        "\n",
        "Incremental learning aims to develop artificially intelligent\n",
        "systems that can continuously learn to address new tasks\n",
        "from new data while preserving knowledge learned from\n",
        "previously learned tasks. There are different incremental learning approaches in the literature.\n",
        "\n",
        "* **Task Incremental**: Models are informed about which task needs to be performed. This is the naive continual learning scenario since task identity is always provided. In this scenario it is possible to train models with task-specific components.\n",
        "\n",
        "* **Domain Incremental**: Identity of the task is not available during the test time. Models, however, only need to solve the task at hand. In other words, they are not required to infer which task it is. Typical examples of this scenario are protocols whereby the structure of the tasks is always the same, but the input-distribution is changing.\n",
        "\n",
        "* **Class Incremental**: The learner does not have access to any information about the task. It must be able to both solve each task seen so far and, at inference time, therefore must be able to distinguish between all classes from all tasks.\n",
        " Some argue that the concept of the class incremental learning is a bit deviated from reality since the structure of the concept does not allow seeing another observation from the same class which is not reasonable in most real case scenarios.\n",
        "\n",
        "* **Task-Free**\n",
        "\n",
        "* **Task-Agnostic**\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src='https://github.com/muratonuryildirim/Tutorials/blob/master/images/continualmnist.png?raw=true' width=600 >\n",
        "\n",
        "To demonstrate the differences between the continual learning scenarios better, let's illustrate an example about MNIST dataset.\n",
        "\n",
        "*Task-IL*: With task given, is it the 1st or 2nd class? (e.g., 0 or 1)\n",
        "\n",
        "*Domain-IL*: With a unknown task, is it a 1st or 2nd class? (e.g., in [0, 2, 4, 6, 8] or in [1, 3, 5, 7, 9])\n",
        "\n",
        "*Class-IL*: With a unknown task, which digit is it? (i.e., choice from 0 to 9)\n"
      ],
      "metadata": {
        "id": "wm_JySrBz91-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Timeline of the Continual Learning\n",
        "\n",
        "### Past Focus\n",
        "The Task-Incremental approach was the initial step in the continual learning setup. It usually consists of a few big tasks. Scientists and researchers had worked on toy datasets to investigate the concepts in detail. The type of the task was mostly supervised and accuracy was the base metric.\n",
        "\n",
        "### Current Focus\n",
        "Even though the Task-Incremental approach still takes place, recently the direction shifted towards to Class-Incremental Learning. Instead of using a few big tasks and experiences, a larger number of experiments is preferred since it is more in line with its nature. However, people still tend to use supervised toy datasets with accuracy metrics.\n",
        "\n",
        "### Future Focus\n",
        "In the future, works based on more realistic datasets with diverse machine learning tasks such as unsupervised learning, and different performance metrics to evaluate are expected. Hence, more practical results about continual learning can be obtained. Besides that, of course, there is still a lot to investigate in the context of continual learning."
      ],
      "metadata": {
        "id": "bhBJn3Dc9V9E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation Protocol of the Continual Learning\n",
        "\n",
        "### Split by Patterns\n",
        "Each experience is split into train-validation-test sets. Test sets are then utilized to evaluate within the experiences. It is a parallel split through the experiences.\n",
        "\n",
        "* *Growing Test Set*:  Considers only the test set of the current and previously encountered experiences. In other words, the number of test sets grows over time as the number of experiences increases by introducing new experiences the model. \n",
        "\n",
        "* *Fixed Test Set*: The number of test sets does not grows over time because it is already fixed to the total number of experiences. This approach makes the evaluation process independent from the as the number of experiences the model have face with. It usually gives more clear view on overall system performance and more common for the benchmarks.\n",
        "\n",
        "<img src='https://github.com/muratonuryildirim/Tutorials/blob/master/images/testset.png?raw=true' width=500 >\n",
        "\n",
        "As an example, imagine continual learning task with an *N* number of experiences: In the *Growing Test Set*, if the model currently in ùëñ<sup>th</sup> experience, then it will be evaluated with ùëñ number of test set which are collected from experiences that have been seen so far. In the *Fixed Test Set*, however, there will be *N* number of test set regardless of the number of experience the model has seen so far. That is why, it is expected to see decreasing accuracy scores in *Growing Test Set* while seeing increasing accuracy scores in the *Fixed Test Set*.\n",
        "\n",
        "### Split by Experiences\n",
        "Experiences are split into two as train and test sets. Model that have been trained with experiences in the train-set is evaluated with the experiences in the test-set. In that approach, main interest is the evalutation of models' ability to learn a never-seen new piece of data which measures the generalization performance. It is a vertical split through the experiences.\n",
        "\n",
        "\n",
        "<img src='https://github.com/muratonuryildirim/Tutorials/blob/master/images/testsplits.png?raw=true' width=1000 >\n",
        "\n",
        "\n",
        "### When to and What to Test?\n",
        "It is common to test the model after each experience. However if finer granularity is wanted then testing after epochs or iterations is also possible.While testing the model, current experience, future experiences and past experiences are available for the evalutation. One can use the all experiences which is *Fixed Test Set* or use only the past and current experiences which is *Growing Test Set*. Besides checking the performance of past, current and future experiences, the model size and its resource consumption such as memory, CPU and GPU should also be monitored.\n",
        "\n",
        "### Evaluation Metrics\n",
        "\n",
        "A common metric accuracy for classification is also used in the continual learning case of course with the consideration of past and future experiences besides the current one. That is why some variations of the accuracy score had been developed. \n",
        "\n",
        "|   | test<sub>e1</sub> | test<sub>e2</sub>  | test<sub>e3</sub>  |\n",
        "|---|------|---|---|\n",
        "| train<sub>e1</sub>|score<sub>1,1</sub>| score<sub>1,2</sub>| score<sub>1,3</sub>|\n",
        "| train<sub>e2</sub>  |score<sub>2,1</sub>|score<sub>2,2</sub>|score<sub>2,3</sub>|\n",
        "| train<sub>e3</sub>|score<sub>3,1</sub>|score<sub>3,2</sub>|score<sub>3,3</sub>|\n",
        "\n",
        "The **ACC metric** checks the accuracy after training on all experiences, and it returns the average accuracy over all the test experiences after completing all the pieces of training. The **A metric** checks the accuracy after the training of a specific experience, and it returns the average accuracy over all the test experiences without completing all the pieces of training.\n",
        "\n",
        "**Forward Transfer Metric (FWT)** checks how much learning the current experience improves learning the *future* experiences. It can be found by subtracting the accuracy score on experience ùëñ without training on the previous experiences from the accuracy score on experience ùëñ with training on the previous experiences. This score is usually averaged out across all experiences. It is actually the average score of the upper triangle in the table (score<sub>1,2</sub>, score<sub>1,3</sub> and score<sub>2,3</sub>).\n",
        "\n",
        "**Backward Transfer Metric (BWT)** checks how much learning the current experience improves learning the *previous* experiences. It can be found by subtracting the accuracy score on experience ùëñ without training on the future experiences from the accuracy score on experience ùëñ with training on the future experiences. This score is usually averaged out across all experiences. It is actually the average score of the lower triangle in the table (score<sub>2,1</sub>, score<sub>3,1</sub> and score<sub>3,2</sub>). Note that if the **BWT** score is negative, then that means forgetting is happening in the model."
      ],
      "metadata": {
        "id": "7foL_Wk7Zcnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vX0qvaQZstt-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}